from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import Any, Dict, List, Optional, cast
from sqlalchemy.ext.asyncio import AsyncSession
from contextlib import asynccontextmanager
import uvicorn
from datetime import datetime
import json
import re
import random
import os
import sys
from pathlib import Path
from dotenv import load_dotenv
from groq import Groq
from openai import OpenAI

# Windows peut d√©marrer avec une console en cp1252 : les emojis dans les logs
# peuvent alors provoquer un UnicodeEncodeError. On force UTF-8 ici.
_stdout_reconfigure = getattr(getattr(sys, "stdout", None), "reconfigure", None)
if callable(_stdout_reconfigure):
    try:
        _stdout_reconfigure(encoding="utf-8", errors="replace")
    except Exception:
        pass

_stderr_reconfigure = getattr(getattr(sys, "stderr", None), "reconfigure", None)
if callable(_stderr_reconfigure):
    try:
        _stderr_reconfigure(encoding="utf-8", errors="replace")
    except Exception:
        pass

# Imports pour la base de donn√©es
from database import get_db, create_tables
from schemas import ChatRequest, ChatResponse, ConversationResponse, ConversationListResponse
import crud

# Charger les variables d'environnement
load_dotenv()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestionnaire du cycle de vie de l'application"""
    # Startup
    await create_tables()
    print("‚úÖ Base de donn√©es initialis√©e")
    yield
    # Shutdown (si n√©cessaire)

app = FastAPI(title="Chatbot API", version="1.0.0", lifespan=lifespan)

# Configuration de l'IA
AI_PROVIDER = os.getenv("AI_PROVIDER", "local").lower()
AI_MODEL = os.getenv("AI_MODEL", "llama-3.3-70b-versatile")

# Initialiser le client IA selon le provider
ai_client = None
if AI_PROVIDER == "groq":
    api_key = os.getenv("GROQ_API_KEY")
    if api_key:
        ai_client = Groq(api_key=api_key)
        print(f"‚úÖ IA activ√©e: Groq avec mod√®le {AI_MODEL}")
    else:
        print("‚ö†Ô∏è GROQ_API_KEY non configur√©e, mode local activ√©")
        AI_PROVIDER = "local"
elif AI_PROVIDER == "openai":
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        ai_client = OpenAI(api_key=api_key)
        AI_MODEL = os.getenv("AI_MODEL", "gpt-3.5-turbo")
        print(f"‚úÖ IA activ√©e: OpenAI avec mod√®le {AI_MODEL}")
    else:
        print("‚ö†Ô∏è OPENAI_API_KEY non configur√©e, mode local activ√©")
        AI_PROVIDER = "local"
else:
    print("‚ÑπÔ∏è Mode local activ√© (sans IA externe)")

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Monter le dossier static
BASE_DIR = Path(__file__).resolve().parent
STATIC_DIR = BASE_DIR / "static"
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")

# Mod√®les de donn√©es (gard√©s pour compatibilit√© avec le code existant)
class Message(BaseModel):
    role: str  # "user" ou "assistant"
    content: str
    timestamp: Optional[str] = None

# Stockage en m√©moire des conversations (obsol√®te, g√©r√© par la BDD)
# conversations = {}

# Contexte utilisateur pour personnalisation
user_context = {}

# Base de connaissances avanc√©e avec patterns et r√©ponses multiples
knowledge_base = {
    "greetings": {
        "patterns": ["bonjour", "salut", "hello", "hey", "coucou", "bonsoir", "hi"],
        "responses": [
            "Bonjour! Ravi de vous parler. Comment puis-je vous aider aujourd'hui?",
            "Salut! Je suis l√† pour vous assister. Que puis-je faire pour vous?",
            "Hello! Content de vous voir. En quoi puis-je vous √™tre utile?",
            "Bonjour! J'esp√®re que vous passez une bonne journ√©e. Comment puis-je vous aider?"
        ]
    },
    "goodbye": {
        "patterns": ["au revoir", "bye", "√† bient√¥t", "salut", "ciao", "adieu"],
        "responses": [
            "Au revoir! N'h√©sitez pas √† revenir si vous avez d'autres questions. üëã",
            "√Ä bient√¥t! Ce fut un plaisir de vous aider.",
            "Au revoir! Prenez soin de vous et revenez quand vous voulez!",
            "Bye! J'esp√®re avoir √©t√© utile. √Ä la prochaine!"
        ]
    },
    "thanks": {
        "patterns": ["merci", "thanks", "thank you", "thx", "merci beaucoup"],
        "responses": [
            "De rien! C'est toujours un plaisir d'aider. üòä",
            "Avec plaisir! N'h√©sitez pas si vous avez d'autres questions.",
            "Je vous en prie! Content d'avoir pu vous aider.",
            "Pas de quoi! Je suis l√† pour √ßa."
        ]
    },
    "identity": {
        "patterns": ["qui es-tu", "qui es tu", "ton nom", "tu es qui", "c'est quoi ton nom", "quel est ton nom"],
        "responses": [
            "Je suis un assistant virtuel intelligent cr√©√© avec FastAPI et Python. Mon but est de vous aider et de r√©pondre √† vos questions!",
            "Je suis votre chatbot personnel, propuls√© par FastAPI. Je peux discuter, r√©pondre √† vos questions et vous assister dans diverses t√¢ches.",
            "Je suis un chatbot IA d√©velopp√© pour vous accompagner. Je combine technologie moderne et conversational design!"
        ]
    },
    "capability": {
        "patterns": ["que peux-tu faire", "tes capacit√©s", "tu peux faire quoi", "aide", "help", "comment tu peux m'aider"],
        "responses": [
            "Je peux discuter avec vous, r√©pondre √† vos questions, vous donner l'heure, faire des calculs, et bien plus! Essayez de me poser une question.",
            "Mes capacit√©s incluent: r√©pondre √† vos questions, faire des calculs math√©matiques, vous donner l'heure et la date, et engager des conversations int√©ressantes.",
            "Je suis l√† pour vous aider de nombreuses fa√ßons! Je peux discuter, calculer, informer, et vous assister dans vos t√¢ches quotidiennes."
        ]
    },
    "mood": {
        "patterns": ["comment vas-tu", "√ßa va", "comment tu vas", "tu vas bien"],
        "responses": [
            "Je vais tr√®s bien, merci de demander! Et vous, comment allez-vous? üòä",
            "Super bien! Je suis toujours pr√™t √† aider. Et vous?",
            "Je vais √† merveille! Heureux d'√™tre √† votre service. Et vous, √ßa va?",
            "Excellent! Je suis en pleine forme virtuelle. Comment vous sentez-vous?"
        ]
    },
    "jokes": {
        "patterns": ["blague", "joke", "fais-moi rire", "raconte une blague", "dr√¥le"],
        "responses": [
            "Pourquoi les plongeurs plongent-ils toujours en arri√®re et jamais en avant? Parce que sinon ils tombent dans le bateau! üòÑ",
            "Qu'est-ce qu'un crocodile qui surveille la pharmacie? Un Lacoste garde! üêä",
            "Qu'est-ce qu'un ordinateur mange au d√©jeuner? Des micro-chips! üíª",
            "Comment appelle-t-on un chat tomb√© dans un pot de peinture le jour de No√´l? Un chat-peint de No√´l! üéÑ"
        ]
    }
}

# Mots-cl√©s pour l'analyse de sentiment
sentiment_keywords = {
    "positive": ["super", "g√©nial", "excellent", "parfait", "merveilleux", "formidable", "top", "cool", "bien", "content", "heureux", "joie"],
    "negative": ["mal", "nul", "mauvais", "horrible", "triste", "d√©√ßu", "probl√®me", "erreur", "bug", "frustr√©", "√©nerv√©"],
    "neutral": ["ok", "moyen", "normal", "standard", "ordinaire"]
}

def analyze_sentiment(message: str) -> str:
    """Analyse le sentiment d'un message"""
    message_lower = message.lower()
    
    positive_count = sum(1 for word in sentiment_keywords["positive"] if word in message_lower)
    negative_count = sum(1 for word in sentiment_keywords["negative"] if word in message_lower)
    
    if positive_count > negative_count:
        return "positive"
    elif negative_count > positive_count:
        return "negative"
    else:
        return "neutral"

def extract_numbers(text: str) -> List[float]:
    """Extrait les nombres d'un texte"""
    numbers = re.findall(r'-?\d+\.?\d*', text)
    return [float(n) for n in numbers]

def calculate_math(message: str) -> Optional[str]:
    """Effectue des calculs math√©matiques simples"""
    message_lower = message.lower()
    numbers = extract_numbers(message)
    
    if len(numbers) < 2:
        return None
    
    # Addition
    if any(word in message_lower for word in ["plus", "+", "additionne", "somme"]):
        result = sum(numbers)
        return f"Le r√©sultat de l'addition est: {result}"
    
    # Soustraction
    if any(word in message_lower for word in ["moins", "-", "soustrait", "diff√©rence"]):
        result = numbers[0] - numbers[1]
        return f"Le r√©sultat de la soustraction est: {result}"
    
    # Multiplication
    if any(word in message_lower for word in ["fois", "*", "√ó", "multipli√©", "multiplie", "produit"]):
        result = numbers[0] * numbers[1]
        return f"Le r√©sultat de la multiplication est: {result}"
    
    # Division
    if any(word in message_lower for word in ["divis√©", "divise", "/", "√∑", "division"]):
        if numbers[1] != 0:
            result = numbers[0] / numbers[1]
            return f"Le r√©sultat de la division est: {result:.2f}"
        else:
            return "Impossible de diviser par z√©ro!"
    
    # Puissance
    if any(word in message_lower for word in ["puissance", "exposant", "^", "**"]):
        result = numbers[0] ** numbers[1]
        return f"Le r√©sultat est: {result}"
    
    return None

def get_contextual_response(message: str, conversation_history: List[Dict]) -> Optional[str]:
    """G√©n√®re des r√©ponses contextuelles bas√©es sur l'historique"""
    message_lower = message.lower()
    
    # R√©f√©rence √† des messages pr√©c√©dents
    if any(word in message_lower for word in ["pr√©c√©dent", "avant", "dernier message", "disais"]):
        if len(conversation_history) >= 2:
            last_bot_message = None
            for msg in reversed(conversation_history[:-1]):
                if msg["role"] == "assistant":
                    last_bot_message = msg["content"]
                    break
            if last_bot_message:
                return f"J'ai dit: '{last_bot_message}'. Voulez-vous en savoir plus?"
    
    # Demande de r√©p√©tition
    if any(word in message_lower for word in ["r√©p√®te", "redis", "encore", "quoi"]) and len(conversation_history) >= 2:
        last_bot_message = None
        for msg in reversed(conversation_history[:-1]):
            if msg["role"] == "assistant":
                last_bot_message = msg["content"]
                break
        if last_bot_message:
            return f"Je r√©p√®te: {last_bot_message}"
    
    return None

def generate_ai_response(user_message: str, conversation_history: List[Dict]) -> Optional[str]:
    """G√©n√®re une r√©ponse en utilisant l'API IA"""
    if not ai_client or AI_PROVIDER == "local":
        return None
    
    try:
        # Pr√©parer les messages pour l'IA
        messages = [
            {
                "role": "system",
                "content": "Tu es un assistant virtuel intelligent, amical et serviable. Tu r√©ponds en fran√ßais de mani√®re claire et concise. Tu peux aider avec diverses t√¢ches, r√©pondre aux questions et avoir des conversations naturelles."
            }
        ]
        
        # Ajouter l'historique de conversation (limit√© aux 10 derniers messages)
        for msg in conversation_history[-10:]:
            messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        # Ajouter le message actuel
        messages.append({
            "role": "user",
            "content": user_message
        })

        messages_for_api = cast(Any, messages)
        
        # Appeler l'API selon le provider
        if AI_PROVIDER == "groq":
            completion = ai_client.chat.completions.create(
                model=AI_MODEL,
                messages=messages_for_api,
                temperature=0.7,
                max_tokens=500,
                top_p=1,
                stream=False
            )
        elif AI_PROVIDER == "openai":
            completion = ai_client.chat.completions.create(
                model=AI_MODEL,
                messages=messages_for_api,
                temperature=0.7,
                max_tokens=500
            )
        else:
            return None
        
        return completion.choices[0].message.content
    
    except Exception as e:
        print(f"‚ùå Erreur IA: {e}")
        return None

def generate_response(user_message: str, conversation_history: List[Dict]) -> str:
    """G√©n√®re une r√©ponse intelligente bas√©e sur le message de l'utilisateur"""
    user_message_lower = user_message.lower().strip()
    
    # 1. Essayer d'utiliser l'IA externe en priorit√©
    if AI_PROVIDER != "local":
        ai_response = generate_ai_response(user_message, conversation_history)
        if ai_response:
            return ai_response
        else:
            print(f"‚ö†Ô∏è L'appel √† l'IA ({AI_PROVIDER}) a √©chou√©. Utilisation du mode local en fallback.")

    # 2. Si l'IA √©choue ou n'est pas configur√©e, utiliser la logique locale
    
    # Analyse de sentiment
    sentiment = analyze_sentiment(user_message)
    
    # R√©ponse contextuelle bas√©e sur l'historique
    contextual_response = get_contextual_response(user_message, conversation_history)
    if contextual_response:
        return contextual_response
    
    # Calculs math√©matiques
    math_result = calculate_math(user_message)
    if math_result:
        return math_result
    
    # Questions sur le temps (priorit√© haute)
    if any(word in user_message_lower for word in ["heure", "time", "quelle heure"]):
        current_time = datetime.now().strftime("%H:%M:%S")
        return f"Il est actuellement {current_time}. ‚è∞"
    
    if any(word in user_message_lower for word in ["date", "jour", "aujourd'hui", "quel jour"]):
        current_date = datetime.now().strftime("%d/%m/%Y")
        day_name = datetime.now().strftime("%A")
        days_fr = {
            "Monday": "lundi", "Tuesday": "mardi", "Wednesday": "mercredi",
            "Thursday": "jeudi", "Friday": "vendredi", "Saturday": "samedi", "Sunday": "dimanche"
        }
        return f"Nous sommes le {days_fr.get(day_name, day_name)} {current_date}. üìÖ"
    
    # Recherche dans la base de connaissances locale
    for category, data in knowledge_base.items():
        for pattern in data["patterns"]:
            if pattern in user_message_lower:
                response = random.choice(data["responses"])
                # Ajouter une touche bas√©e sur le sentiment
                if sentiment == "positive":
                    response += " Vous semblez de bonne humeur! üòä"
                return response
    
    # R√©ponses intelligentes bas√©es sur le type de message
    if "?" in user_message:
        questions_responses = [
            f"C'est une excellente question! Pour r√©pondre √† '{user_message}', j'aurais besoin de plus de contexte. Pouvez-vous pr√©ciser?",
            f"Int√©ressant comme question! Je r√©fl√©chis √† '{user_message}'. Pouvez-vous me donner plus de d√©tails?",
            f"Belle question! Concernant '{user_message}', pourriez-vous √™tre plus sp√©cifique pour que je puisse mieux vous aider?"
        ]
        return random.choice(questions_responses)
    
    # D√©tection de programmation
    if any(word in user_message_lower for word in ["python", "code", "programmation", "d√©veloppement", "fastapi", "api"]):
        return "Ah, un passionn√© de programmation! Python et FastAPI sont d'excellents choix. Comment puis-je vous aider avec votre projet de d√©veloppement? üíª"
    
    # R√©ponses bas√©es sur le sentiment
    if sentiment == "negative":
        return "Je sens que quelque chose ne va pas. Comment puis-je vous aider √† r√©soudre ce probl√®me? Je suis l√† pour vous assister. ü§ù"
    
    if sentiment == "positive":
        return "C'est g√©nial! Votre enthousiasme est contagieux! Comment puis-je contribuer √† votre bonne humeur? üòÑ"
    
    # R√©ponses vari√©es par d√©faut
    default_responses = [
        f"Int√©ressant! Vous dites '{user_message}'. Pouvez-vous m'en dire plus?",
        f"J'ai bien not√©: '{user_message}'. Comment puis-je vous aider avec cela?",
        f"Merci pour ce message. Concernant '{user_message}', que souhaitez-vous savoir exactement?",
        "Je comprends ce que vous dites. Voulez-vous que je d√©veloppe sur un aspect particulier?",
        "C'est not√©! Y a-t-il quelque chose de sp√©cifique que vous aimeriez que je fasse?"
    ]
    
    return random.choice(default_responses)

@app.get("/")
async def root():
    """Page d'accueil - retourne l'interface HTML"""
    return FileResponse(str(STATIC_DIR / "index.html"))

@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest, db: AsyncSession = Depends(get_db)):
    """Endpoint principal pour le chat avec base de donn√©es"""
    try:
        # R√©cup√©rer ou cr√©er une conversation
        if request.conversation_id:
            conversation = await crud.get_conversation(db, request.conversation_id)
            if not conversation:
                conversation = await crud.create_conversation(db, request.user_name)
        else:
            conversation = await crud.create_conversation(db, request.user_name)
        
        conversation_id = conversation.conversation_id
        
        # Sauvegarder le message de l'utilisateur dans la BDD
        await crud.create_message(
            db=db,
            conversation_id=conversation_id,
            role="user",
            content=request.message
        )
        
        # R√©cup√©rer l'historique pour le contexte
        messages_db = await crud.get_messages(db, conversation_id)
        conversation_history = [
            {"role": msg.role, "content": msg.content}
            for msg in messages_db
        ]
        
        # G√©n√©rer la r√©ponse avec le contexte de conversation
        bot_response_text = generate_response(request.message, conversation_history)
        
        # Sauvegarder la r√©ponse du bot dans la BDD
        bot_message = await crud.create_message(
            db=db,
            conversation_id=conversation_id,
            role="assistant",
            content=bot_response_text
        )
        
        return ChatResponse(
            response=bot_response_text,
            conversation_id=conversation_id,
            timestamp=datetime.now().isoformat(),
            message_id=bot_message.id
        )
    
    except Exception as e:
        print(f"‚ùå Erreur chat: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/conversation/{conversation_id}")
async def get_conversation_endpoint(conversation_id: str, db: AsyncSession = Depends(get_db)):
    """R√©cup√®re l'historique d'une conversation depuis la BDD"""
    conversation = await crud.get_conversation(db, conversation_id)
    if not conversation:
        raise HTTPException(status_code=404, detail="Conversation non trouv√©e")
    
    return {
        "conversation_id": conversation.conversation_id,
        "user_name": conversation.user_name,
        "created_at": conversation.created_at.isoformat(),
        "messages": [
            {
                "role": msg.role,
                "content": msg.content,
                "timestamp": msg.timestamp.isoformat()
            }
            for msg in conversation.messages
        ]
    }

@app.delete("/api/conversation/{conversation_id}")
async def delete_conversation_endpoint(conversation_id: str, db: AsyncSession = Depends(get_db)):
    """Supprime une conversation de la BDD"""
    deleted = await crud.delete_conversation(db, conversation_id)
    if not deleted:
        raise HTTPException(status_code=404, detail="Conversation non trouv√©e")
    
    return {"message": "Conversation supprim√©e avec succ√®s"}

@app.get("/api/conversations")
async def list_conversations_endpoint(skip: int = 0, limit: int = 100, db: AsyncSession = Depends(get_db)):
    """Liste toutes les conversations depuis la BDD"""
    conversations_db = await crud.get_conversations(db, skip, limit)
    
    conversations_list = []
    for conv in conversations_db:
        message_count = await crud.get_message_count(db, conv.id)
        conversations_list.append({
            "conversation_id": conv.conversation_id,
            "user_name": conv.user_name,
            "message_count": message_count,
            "created_at": conv.created_at.isoformat(),
            "updated_at": conv.updated_at.isoformat()
        })
    
    return {
        "total": len(conversations_list),
        "conversations": conversations_list
    }

@app.get("/api/stats")
async def get_stats(db: AsyncSession = Depends(get_db)):
    """Obtenir des statistiques sur les conversations"""
    stats = await crud.get_conversation_stats(db)
    return {
        "status": "success",
        "statistics": stats,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """Endpoint de sant√©"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
